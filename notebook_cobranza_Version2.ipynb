{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cobranza (Recuperaci√≥n de Cartera)\n",
    "\n",
    "Notebook para predecir la probabilidad de recuperaci√≥n de deudas usando datos sint√©ticos o CSV externo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "# Verificar que todas las librer√≠as est√©n importadas correctamente\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente:\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"XGBoost: {xgb.__version__}\")\n",
    "print(f\"Optuna: {optuna.__version__}\")\n",
    "\n",
    "# Verificar hardware disponible\n",
    "print(f\"\\nüñ•Ô∏è Hardware disponible:\")\n",
    "print(f\"CPU Cores: {psutil.cpu_count(logical=False)} f√≠sicos, {psutil.cpu_count(logical=True)} l√≥gicos\")\n",
    "print(f\"RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "print(f\"RAM disponible: {psutil.virtual_memory().available / (1024**3):.1f} GB\")\n",
    "\n",
    "# Verificar soporte GPU para XGBoost\n",
    "try:\n",
    "    import subprocess\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"üéÆ GPU NVIDIA detectada - XGBoost puede usar GPU\")\n",
    "        GPU_AVAILABLE = True\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è GPU NVIDIA no detectada - usando CPU\")\n",
    "        GPU_AVAILABLE = False\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è No se pudo verificar GPU - usando CPU\")\n",
    "    GPU_AVAILABLE = False\n",
    "\n",
    "print(\"üöÄ Listo para optimizaci√≥n bayesiana optimizada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar datos\n",
    "### A) Generar datos sint√©ticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# Generar dataset m√°s grande aprovechando la RAM (64GB)\n",
    "n = 10000  # 10x m√°s datos para mejor entrenamiento\n",
    "print(f\"üìä Generando dataset de cobranza con {n:,} registros...\")\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'dias_atraso': np.random.randint(0, 180, n),  # M√°s rango de d√≠as\n",
    "    'monto_deuda': np.random.lognormal(6, 1, n),  # Distribuci√≥n m√°s realista\n",
    "    'pagos_previos': np.random.poisson(2, n),     # Distribuci√≥n de Poisson\n",
    "    'contactos': np.random.poisson(3, n),         # M√°s contactos\n",
    "    'segmento': np.random.choice(['Retail','Pyme','Corporativo','Empresarial'], n, p=[0.5, 0.3, 0.15, 0.05]),\n",
    "    'edad_cliente': np.random.randint(18, 80, n),\n",
    "    'ingresos_mensuales': np.random.lognormal(8, 0.5, n),\n",
    "    'score_credito': np.random.normal(650, 100, n),\n",
    "    'productos_activos': np.random.randint(1, 6, n),\n",
    "})\n",
    "\n",
    "# Generar variable objetivo (pago) m√°s realista\n",
    "pago_prob = (\n",
    "    0.3 * (data['dias_atraso'] < 30) +                    # Pago temprano\n",
    "    0.2 * (data['pagos_previos'] > 2) +                   # Historial de pagos\n",
    "    0.15 * (data['contactos'] > 3) +                      # Muchos contactos\n",
    "    0.1 * (data['monto_deuda'] < data['ingresos_mensuales'] * 0.3) +  # Deuda baja vs ingresos\n",
    "    0.1 * (data['score_credito'] > 700) +                 # Buen score crediticio\n",
    "    0.05 * (data['segmento'].isin(['Corporativo', 'Empresarial'])) +  # Segmento premium\n",
    "    np.random.rand(n) * 0.1                               # Ruido aleatorio\n",
    ")\n",
    "\n",
    "data['pago'] = (pago_prob > 0.4).astype(int)\n",
    "print(f\"‚úÖ Dataset generado: {data.shape[0]:,} filas x {data.shape[1]} columnas\")\n",
    "print(f\"üìà Tasa de pago: {data['pago'].mean():.2%}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Cargar datos desde CSV\n",
    "> Descomenta y ajusta la ruta si tienes tu propio archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('deudas_cobranza.csv')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['pago'].value_counts())\n",
    "data.describe()\n",
    "data.groupby('segmento')['pago'].mean().plot(kind='bar')\n",
    "plt.title('Tasa de pago por segmento')\n",
    "plt.ylabel('Pago Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('pago', axis=1)\n",
    "y = data['pago']\n",
    "X['segmento'] = LabelEncoder().fit_transform(X['segmento'])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelos\n",
    "### A) Regresi√≥n Log√≠stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=200)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluaci√≥n y visualizaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee47c16",
   "metadata": {},
   "source": [
    "## 6. Optimizaci√≥n Bayesiana con Optuna\n",
    "\n",
    "Vamos a optimizar los hiperpar√°metros de ambos modelos usando optimizaci√≥n bayesiana para mejorar el rendimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n objetivo para Regresi√≥n Log√≠stica\n",
    "def objective_lr(trial):\n",
    "    # Definir el espacio de b√∫squeda de hiperpar√°metros\n",
    "    C = trial.suggest_float('C', 0.01, 100.0, log=True)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000)\n",
    "    \n",
    "    # Seleccionar solver compatible con la penalty\n",
    "    if penalty == 'elasticnet':\n",
    "        solver = 'saga'\n",
    "    elif penalty == 'l1':\n",
    "        solver = trial.suggest_categorical('solver_l1', ['liblinear', 'saga'])\n",
    "    else:  # penalty == 'l2'\n",
    "        solver = trial.suggest_categorical('solver_l2', ['liblinear', 'lbfgs', 'saga'])\n",
    "    \n",
    "    # Crear y entrenar el modelo\n",
    "    model = LogisticRegression(\n",
    "        C=C, \n",
    "        penalty=penalty, \n",
    "        solver=solver, \n",
    "        max_iter=max_iter,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Validaci√≥n cruzada con manejo de errores\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        return scores.mean()\n",
    "    except Exception as e:\n",
    "        return 0.0\n",
    "\n",
    "# Funci√≥n para crear modelo optimizado con par√°metros mapeados correctamente\n",
    "def create_optimized_lr_model(best_params):\n",
    "    \"\"\"Crea un modelo de regresi√≥n log√≠stica con los par√°metros optimizados\"\"\"\n",
    "    params = {\n",
    "        'C': best_params['C'],\n",
    "        'penalty': best_params['penalty'],\n",
    "        'max_iter': best_params['max_iter'],\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    if best_params['penalty'] == 'elasticnet':\n",
    "        params['solver'] = 'saga'\n",
    "    elif best_params['penalty'] == 'l1':\n",
    "        params['solver'] = best_params.get('solver_l1', 'liblinear')\n",
    "    else:  # penalty == 'l2'\n",
    "        params['solver'] = best_params.get('solver_l2', 'liblinear')\n",
    "    \n",
    "    return LogisticRegression(**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n objetivo para XGBoost (optimizada para hardware potente)\n",
    "def objective_xgb(trial):\n",
    "    # Definir el espacio de b√∫squeda de hiperpar√°metros (ampliado para mejor hardware)\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),  # M√°s √°rboles\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),            # Mayor profundidad\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 20),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 20),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'random_state': 42,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    \n",
    "    # Usar GPU si est√° disponible\n",
    "    if GPU_AVAILABLE:\n",
    "        params.update({\n",
    "            'tree_method': 'gpu_hist',\n",
    "            'gpu_id': 0,\n",
    "            'predictor': 'gpu_predictor'\n",
    "        })\n",
    "    else:\n",
    "        params['tree_method'] = 'hist'  # CPU optimizado\n",
    "    \n",
    "    # Crear y entrenar el modelo\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    # Validaci√≥n cruzada con manejo de errores\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        return scores.mean()\n",
    "    except Exception as e:\n",
    "        return 0.0\n",
    "\n",
    "# Funci√≥n para crear modelo XGBoost optimizado\n",
    "def create_optimized_xgb_model(best_params):\n",
    "    \"\"\"Crea un modelo XGBoost con los par√°metros optimizados\"\"\"\n",
    "    params = best_params.copy()\n",
    "    params['random_state'] = 42\n",
    "    params['eval_metric'] = 'logloss'\n",
    "    return xgb.XGBClassifier(**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff703e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizaci√≥n para Regresi√≥n Log√≠stica (optimizada para hardware potente)\n",
    "print(\"üîç Optimizando Regresi√≥n Log√≠stica...\")\n",
    "study_lr = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\n",
    "study_lr.optimize(objective_lr, n_trials=200, n_jobs=-1)  # M√°s trials + paralelizaci√≥n\n",
    "\n",
    "print(f\"Mejor score: {study_lr.best_value:.4f}\")\n",
    "print(f\"Mejores par√°metros: {study_lr.best_params}\")\n",
    "\n",
    "# Optimizaci√≥n para XGBoost (optimizada para hardware potente)\n",
    "print(\"\\nüîç Optimizando XGBoost...\")\n",
    "study_xgb = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\n",
    "study_xgb.optimize(objective_xgb, n_trials=200, n_jobs=-1)  # M√°s trials + paralelizaci√≥n\n",
    "\n",
    "print(f\"Mejor score: {study_xgb.best_value:.4f}\")\n",
    "print(f\"Mejores par√°metros: {study_xgb.best_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf728a3",
   "metadata": {},
   "source": [
    "## 7. Modelos Optimizados\n",
    "\n",
    "Ahora entrenamos los modelos con los mejores hiperpar√°metros encontrados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d12e58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Regresi√≥n Log√≠stica optimizada\n",
    "lr_optimized = create_optimized_lr_model(study_lr.best_params)\n",
    "lr_optimized.fit(X_train, y_train)\n",
    "y_pred_lr_opt = lr_optimized.predict(X_test)\n",
    "\n",
    "print(\"üìä Regresi√≥n Log√≠stica Optimizada:\")\n",
    "print(classification_report(y_test, y_pred_lr_opt))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr_opt):.4f}\")\n",
    "\n",
    "# Entrenar XGBoost optimizado\n",
    "xgb_optimized = create_optimized_xgb_model(study_xgb.best_params)\n",
    "xgb_optimized.fit(X_train, y_train)\n",
    "y_pred_xgb_opt = xgb_optimized.predict(X_test)\n",
    "\n",
    "print(\"\\nüìä XGBoost Optimizado:\")\n",
    "print(classification_report(y_test, y_pred_xgb_opt))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb_opt):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n de accuracy\n",
    "results_comparison = pd.DataFrame({\n",
    "    'Modelo': ['Regresi√≥n Log√≠stica Original', 'Regresi√≥n Log√≠stica Optimizada', \n",
    "               'XGBoost Original', 'XGBoost Optimizado'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_lr),\n",
    "        accuracy_score(y_test, y_pred_lr_opt),\n",
    "        accuracy_score(y_test, y_pred_xgb),\n",
    "        accuracy_score(y_test, y_pred_xgb_opt)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"üìà Comparaci√≥n de Resultados:\")\n",
    "print(results_comparison)\n",
    "\n",
    "# Visualizaci√≥n de la comparaci√≥n\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(results_comparison['Modelo'], results_comparison['Accuracy'])\n",
    "plt.title('Comparaci√≥n de Accuracy - Cobranza')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(0.5, 0.9)\n",
    "\n",
    "# Mejora en accuracy\n",
    "improvements = [\n",
    "    results_comparison.iloc[1, 1] - results_comparison.iloc[0, 1],  # LR improvement\n",
    "    results_comparison.iloc[3, 1] - results_comparison.iloc[2, 1]   # XGB improvement\n",
    "]\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(['Regresi√≥n Log√≠stica', 'XGBoost'], improvements, color=['blue', 'green'])\n",
    "plt.title('Mejora en Accuracy')\n",
    "plt.ylabel('Mejora')\n",
    "plt.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüéØ Mejoras obtenidas:\")\n",
    "print(f\"Regresi√≥n Log√≠stica: +{improvements[0]:.4f} ({improvements[0]*100:.2f}%)\")\n",
    "print(f\"XGBoost: +{improvements[1]:.4f} ({improvements[1]*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Confusi√≥n LR')\n",
    "plt.imshow(confusion_matrix(y_test, y_pred_lr), cmap='Blues')\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Confusi√≥n XGBoost')\n",
    "plt.imshow(confusion_matrix(y_test, y_pred_xgb), cmap='Greens')\n",
    "plt.show()\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, lr.predict_proba(X_test)[:,1])\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, xgb_model.predict_proba(X_test)[:,1])\n",
    "plt.plot(fpr_lr, tpr_lr, label='LogisticReg')\n",
    "plt.plot(fpr_xgb, tpr_xgb, label='XGBoost')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()\n",
    "plt.title('Curvas ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Importancia de variables\n",
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgb_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comentarios finales\n",
    "- Puedes modificar los par√°metros, probar con CSV propio y agregar nuevas visualizaciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
